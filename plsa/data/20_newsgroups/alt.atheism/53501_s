
 in article <1993apr17.045559.12900@ousrvr.oulu.fi>
 kempmp@phoenix.oulu.fi (petri pihko) writes:
 
 >kevin anthoney (kax@cs.nott.ac.uk) wrote:
 >
 >: this post is probably either brilliant or insane. do let me know
 >: which... :-)
 >
 >a brilliant example of using the introspective objection against 
 >materialist theories of consciousness.
 
 diplomatic :-)
 
 i realize i'm fighting occam's razor in this argument, so i'll try to
 explain why i feel a mind is necessary. 
 
 firstly, i'm not impressed with the ability of algorithms. they're
 great at solving problems once the method has been worked out, but not
 at working out the method itself.
 
 as a specific example, i like to solve numerical crosswords (not the
 simple do-the-sums-and-insert-the-answers type, the hard ones.) to do
 these with any efficiency, you need to figure out a variety of tricks.
 now, i know that you can program a computer to do these puzzles, but
 in doing so you have to work out the tricks _yourself_, and program
 them into the computer. you can, of course, 'obfuscate' the trick, and
 write the program so that it is uncovered, but as far as i can see,
 the trick still has to be there in some form to be discovered. does
 this mean that all the ideas we will ever have are already
 pre-programmed into our brains? this is somewhat unlikely, given that
 our brains ultimately are encoded in 46 chromosomes worth of genetic
 material, much of which isn't used.
 
 one way around this is to bring the environment into the equation, but
 (again, as far as i can see) this still has an air of 'if you see
 object x, then perform action y,' and we don't seem to get anywhere.
 the algorithm has to anticipate what it might see, and what
 conclusions to draw from it's experience.
 
 the other problem with algorithms is their instability. not many
 algorithms survive if you take out a large portion of their code, yet
 people survive strokes without going completely haywire (there are
 side-effects, but patients still seem remarkably stable.) also,
 neurons in perfectly healthy people are dying at an alarming rate -
 can an algorithm survive if i randomly corrupt various bits of it's
 code?
 
 the next problem is the sticky question of "what is colour?" (replace
 'colour' with the sensation of your choice.) presumably, the
 materialist viewpoint is that it's the product of some kind of
 chemical reaction. the usual products of such a reaction are energy +
 different chemicals. is colour a mixture of these? if this is so, a
 computer won't see colour, because the chemistry is different. does an
 algorithm that sees colour have a selective advantage over an
 equivalent that doesn't? it shouldn't, because the outputs of each
 algorithm ought to be the same in equivalent circumstances. so why do
 we see colour?
 
 
 >
 >however, such a view is actually a nonsolution. how should minds be
 >able to act as observers, feel pain and pleasure and issue
 >commands any better than the brain? moreover, how do the interactions
 >occur?
 
 a bit of idle speculation...
 
 if i remember correctly, quantum mechanics consists of a wavefunction,
 with two processes acting on it. the first process has been called
 'unitary evolution' (or 'u'), is governed by schroedinger's equation
 and is well known. the second process, called various things such as
 'collapse of the wavefunction' or 'state vector reduction' (or 'r'),
 and is more mysterious. it is usually said to occur when a
 'measurement' takes place, although nobody seems to know precisely
 when that occurs. when it does occur, the effect of r is to abruptly
 change the wavefunction.
 
 i envisage r as an interaction between the wavefunction and 'something
 else,' which i shall imaginitively call 'part x.' it seems reasonable
 to assume that _something_ causes r, although that something might be
 the wavefunction itself (in which case, part x is simply the
 wavefunction. note, though, that we'd need more than u to explain r.)
 
 anyway, i'm speculating that minds would be in part x. there seems to
 be some link between consciousness and r, in that we never see linear
 superpositions of anything, although there are alternative
 explainations for this. i've no idea how a brain is supposed to access
 part x, but since this is only speculation, that won't matter too
 much :-) my main point is that there might be a place for minds in
 physics.
 
 i'll go back to my nice padded cell now, if that's ok with you :-)
 
 >
 >
 >petri
 
 -- 
 ------------------------------------------------------------------------
 kevin anthoney                                         kax@cs.nott.ac.uk
             don't believe anything you read in .sig files.
 ------------------------------------------------------------------------
 