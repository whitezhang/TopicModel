
 in article <1r2m21$8mo@fido.asd.sgi.com> livesey@solntze.wpd.sgi.com (jon livesey) writes:
 >in article <1993apr19.151902.21216@st-andrews.ac.uk>, nrp@st-andrews.ac.uk (norman r. paterson) writes:
 ...
 >|> >you're admitting a lot more than that.  you are admitting that
 >|> >your morals are situational.   you are admitting that the actions
 >|> >of other people and the situation you are in help to determine
 >|> >how you judge the moral significance of one of your own actions.
 ...
 >|> >for what it's worth - and yes, i know you claim to be an agnostic -
 >|> >it's this ability to re-label things from "immoral" to "moral" 
 >|> >that i find one of the *least* attractive qualities of the religious
 >|> >mind.
 >|> >
 >|> >jon.
 ...
 >|> from my reading i discovered that this is not yet possible, and may not be
 >|> possible in principle.  the reason is that every case that comes to trial
 >|> is unique, with its own collection of special facts.  it is beyond human
 >|> power to specify all the possible circumstances that may bear upon a case
 >|> in advance.  we have to judge each one on its own merits, and simply take
 >|> the formal law as a guide.  the law is an ass: we must be careful to use
 >|> it as a beast of burden and not expect anything more from it.
 ...
 >|> -norman
 >
 >just as well, then, that i'm not claiming that my own moral system is
 >absolute.
 >
 >jon.
 >
 >[list of references stretching from here to alpha centauri deleted.]
 
 jon-
 
 [and i thought to impress with my references!]
 
 ok, so you don't claim to have an absolute moral system.  do you claim
 to have an objective one?  i'll assume your answer is "yes," apologies
 if not.
 
 "objective" means is that different observers will get the same results.
 the observers may need to be trained in the use of the system.  i'd be
 interested in seeing a summary of your system, though i appreciate that
 it might take a great deal of effort to put it in writing.
 
 in your post above you objected to "situational morals."  perhaps you
 could begin by explaining how you objectively set the situational
 boundaries of an act, in your system.  i don't think you can do it.
 here's a game we could play that would illustrate my point.  i think of
 a situation, and you have to say whether it is moral or not, and why.
 in your move you can
 
 	1) ask me any objective question about the situation, or
 	2) pronounce judgement.
 
 after you have pronounced judgement, i get to add whatever context i like
 to the situation, provided i don't change anything i have already said.
 if i can change the context to one where your objective system would give
 a different answer, then your system is faulty.  (since i don't know what
 your system is, either you must write it down, or at least be consistent.)
 
 do you think your system could pass this test?
 
 -norman
 