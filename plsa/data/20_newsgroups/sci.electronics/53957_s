
 one not-so-quick question to throw out there for you guys...
 
 for our class project, we need to design and build a power supply
 to the following specs:
 
 voltatge:  adjustable from 1-12v
 current:   *limited* at 1a
 
 voltage must stay within 2% of designated value for i from 0-1a
 ac ripple less than 5 mv (rms)
 
 of course, we can't just use an adjustable voltage, current-limiting
 regulator chip ;^)
 
 our problem is with the current limiting (i.e. we've found stuff to
 do the rest of the parts of the circuit).  what the supply must do,
 if presented with a load which would draw more than 1a, given the
 supply voltage, is reduce the voltage so that the current will equal
 one amp.  thus, if we were to short the thing with the ammeter, we
 should read one amp.  if we measure the current through a 1 ohm 
 resistor at 12v, we should read one amp (and the output voltage, by
 necessity, must be 1v.
 
 the only basic idea we have seen for the current limiter involves
 a circuit which will pull current off of the base of the output 
 power transistor, and therefore reduce the output.
 
 so, does anybody have any ideas we could work from?
 
 thanks in advance.
 
 andy collins, kc6yey
 acollins@uclink.berkeley.edu
 
 ps: if anybody wants to flame this as a stupid project, i agree fully,
     but i still have to do it, its graded ;^)
 
 