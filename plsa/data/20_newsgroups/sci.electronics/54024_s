
 in article <72020037@otter.hpl.hp.com> tgg@otter.hpl.hp.com (tom gardner) writes:
 >in sci.electronics, rgc3679@bcstec.ca.boeing.com (robert g. carpenter) writes:
 >
 >> i'm wondering if it's possible to use radio waves to measure the
 >> distance between a transmitter(s) and receiver?
 >
 >yes. it's called radar.
 well, actually not quite. both radar and radio-altimeters measure distances
 by measuring the time required to transmit a signal, then receive its
 reflection from a target. radar generally uses pulses, while radio altimeters
 use either pulses or a modulated continuous-wave transmission. in the case of
 the latter, highly accurate distance measurement can be made. as an example,
 the original bendix ala-52 radio altimeter was accurate to 1/8 foot at 2500
 feet altitude.
 
 note, however that this is a different method of measuring than the poster
 originally asked about. the problem with gaining accurate measurements between
 a transmitter and a seperate receiver is that you need a highly accurate
 time base which starts at the receiver at the exact instant the transmitter
 triggers. this cannot be wire connected, since radio waves will actually
 travel faster in free-space (air, in this case) than wire (the difference
 is called the velocity factor of the cable). so you need to resort to a
 common timebase that is automatically corrected for distance, etc. something
 like a pll connected to a gps receiver should do the trick, triggering both
 the transmitter and receiver simultaneously. sound expensive? not too bad,
 but plan on spending a few bucks in both equipment and effort.
 
 why not go to a different method? surveyors use a laser-light system where again
 the reflection time is measured. why not try this? (sounds like something a p.e.
 should know about anyway ;-).
 
 >> seems to me that you should be able to measure the signal strength
 >> and determine distance. this would be for short distances (2000 ft),
 >> and i would need to have accuracy of 6 inches, or so.
 
 this is actually highly inaccurate, since the power output of a transmitter
 varies from unit to unit, there are variances in the antenna and transmission
 line, and the receiver may also vary, both from unit to unit, and the same unit
 over time. you would need to continuously calibrate the entire system. with
 the radio altimeter this is also done, but since everything is located at
 one place, it is much easier to do. note especially that the time base for
 the r.a. receiver and transmitter is one unit also...
 
 >depends on the environment: in a static environent such as a waveguide yes, in
 >a dynamic environment (with objects moving about) the multipath kills this
 >concept.
 
 nope. fm capture effect says that the strongest signal wins. that is, unless
 the two interfering signals are seperated by more than 3 db in signal strength.
 this is the one problem that makes altimeters inaccurate at very low altitudes.
 signals bouncing off runways tend to be very strong...
 
 >> what frequencies would be best for this? or does matter?
 
 as high as possible to eliminate outside influence, and also to enhance
 attenuation of multipath signals. radio altimeters typically use frequencies
 around 4 ghz.
 
 hope this helps...
 
 -- 
 ==========================================================
 jack brindle
 ham radio: wa4fib
 internet: jackb@mdd.comm.mot.com
 