
 kevin anthoney (kax@cs.nott.ac.uk) wrote:
 
 (about my reply)
 
 > diplomatic :-)
 
 it a society that is constantly on the verge of flaming, usenet, diplomacy
 is the best way to ensure the voice of reason gets through, isn't it?
 
 > i realize i'm fighting occam's razor in this argument, so i'll try to
 > explain why i feel a mind is necessary. 
 
 kevin, unfortunately you are now delving into field i know too little
 about, algorithms. your reasoning, as i see it, is very much along the
 lines of roger penrose, who claimed that mathematical 'insight' cannot
 be algorithmic in his book _the emperor's new mind: concerning
 computers, minds, and the laws of physics_. however, penrose's
 claim that he _has_ mathematical insight, or your similar claim
 that wavefunctions collapse only when we consciously take a look,
 could be just illusions.
 
 we are obviouslu taking very different viewpoints - i try to ponder
 on the problem of consciousness from an evolutionary perspective,
 realising that it might not be anything special, but certainly
 useful. thinking back of what i wrote, do you think worms have minds
 or not? they are able to experience pain, at least they behave 
 just like that. yet it is conceivable that we might some day
 in the future perform a "total synthesis of c. elegans" from
 the elements. would such a worm have a mind?
 
 > firstly, i'm not impressed with the ability of algorithms. they're
 > great at solving problems once the method has been worked out, but not
 > at working out the method itself.
 
 this is true to some extent. however, i do not think that our brains
 work like computers, at all. in fact, there is substantial evidence
 (skarda, 1985; skarda & freeman 1987) that brains work more or less
 chaotically, generating enough randomness for mental states to evolve.
 our brains work much like genetic algorithm generators, i suppose.
 
 > the trick still has to be there in some form to be discovered. does
 > this mean that all the ideas we will ever have are already
 > pre-programmed into our brains? this is somewhat unlikely, given that
 > our brains ultimately are encoded in 46 chromosomes worth of genetic
 > material, much of which isn't used.
 
 indeed, this is extremely unlikely, given the vast impact of nurture
 on our mind and brain. i suggest, however, that before trying to
 understand our consciousness as a collection of algorithms. 
 
 kevin, take a look at the references i mentioned, and think again.
 i still think the best experts on the nature of a conscious mind
 are neurologists, neuropsychologists and biologists (but do not 
 flame me for my opinions), since they study beings that are
 conscious. 
 
 the reason i am repeating my advice is that this discussion cannot
 lead to anywhere if our backgrounds are too different.
 
 and please, do not bring qm into this discussion at all - not
 all physicists are happy with the claim that our consciousness
 plays some special role in physics. i would say it doesn't.
 
 > the other problem with algorithms is their instability. not many
 > algorithms survive if you take out a large portion of their code, yet
 > people survive strokes without going completely haywire (there are
 > side-effects, but patients still seem remarkably stable.) also,
 > neurons in perfectly healthy people are dying at an alarming rate -
 > can an algorithm survive if i randomly corrupt various bits of it's
 > code?
 
 again, _brains are not computers_. don't forget this. this does not
 mean they need something else to work - they just work differently.
 their primary 'purpose' is perception and guidance of action, 
 self-awareness and high intelligence are later appearances.
 
 > the next problem is the sticky question of "what is colour?" (replace
 > 'colour' with the sensation of your choice.) presumably, the
 > materialist viewpoint is that it's the product of some kind of
 > chemical reaction. the usual products of such a reaction are energy +
 > different chemicals. is colour a mixture of these?
 
 you are still expecting that we could find the idea of 'green' in
 our brains somewhere, perhaps in the form of some chemical. this is
 not how i see it. the sensation 'green' is a certain time-dependent
 pattern in the area v4 of our visual cortex, and it is distributed
 with the help of areas v1 and v2 to the rest of the brain. 
 
 indeed, a firing pattern. i have sometimes thought of our consciousness
 as a global free induction pattern of these local firing patterns,
 but this is just idle speculation.
 
 scientific american's september 1992 issue was a special issue on
 mind and brain. have you already read it from cover to cover? ;-)
 there are two articles on visual perception, so you might be 
 interested.
 
 but again, please note that subjective experiences cannot be 
 observed from a third-person perspective. if we see nothing but 
 neuronal activity, we cannot go on to conclude that this is not the
 mind.
 
 kalat (1988) writes about numerous examples where electric stimulation
 of different areas of brain have led to various changes in the 
 patients' state of mind. for instance, a patient whose septal area
 was stimulated (without his knowledge) by remote control during
 a psychiatric interview was quickly cured of his depression, and
 started discussing a plan to seduce his girlfriend.
 
 stimulations in the temporal lobe have sometimes led to embarrassing
 situations, when the patients have started flirting with the
 therapist.
 
 in conclusion, there is evidence that
 
 1) brains are essentially necessary for subjective experiences, 
    brain damage is usually equivalent to some sort of mind damage
 
 2) conscious processes involve substantial brain activity in
    various areas of brain - when we think of colours, our
    visual cortex is activated etc.
 
 3) consciousness is an afterthought - we become conscious of our
    actions with a half a second delay, and our brains are ahead
    of our 'conscious will' by at least 350 ms. 
 
 thus, i think it is fruitful to turn the question "why do 'i' see
 colours" around and ask "what is this 'i' that seems to be 
 observing?", since it seems that our conscious mind is not
 the king of our brains.
 
 > if this is so, a
 > computer won't see colour, because the chemistry is different. does an
 > algorithm that sees colour have a selective advantage over an
 > equivalent that doesn't? it shouldn't, because the outputs of each
 > algorithm ought to be the same in equivalent circumstances. so why do
 > we see colour?
 
 this depends on what is meant by 'seeing colours'. does a neural
 network that is capable of recognising handwritten numbers from
 0 to 9 see the numbers, if it is capable of sorting them?
 
 if you are asking, "why does an animal who is conscious of itself
 as an observer have an evolutionary advantage over an animal who
 doesn't", i have a good answer - read my previous posting,
 where i wrote why a sense of identity helps social animals to swap
 roles and act more morally, so that they don't unconsciously
 kill each other with newly discovered weapons. (a bit extreme,
 but this is the basic idea.)
 
 when early _homo_ became more and more efficient in using tools, 
 a sense of identity and the concept of 'self' had to evolve in
 line with this development. indeed, respect for others and 
 conscious altruistic behaviour might be evolutionary advantages
 for social animals, such as early humans. 
 
 > if i remember correctly, quantum mechanics consists of a wavefunction,
 > with two processes acting on it. the first process has been called
 > 'unitary evolution' (or 'u'), is governed by schroedinger's equation
 > and is well known. the second process, called various things such as
 > 'collapse of the wavefunction' or 'state vector reduction' (or 'r'),
 > and is more mysterious. it is usually said to occur when a
 > 'measurement' takes place, although nobody seems to know precisely
 > when that occurs. when it does occur, the effect of r is to abruptly
 > change the wavefunction.
 
 if minds are required for this, does this mean that until human
 minds came to the scene, wavefunctions never collapsed, but remained
 in the superpositions for aeons? my, how powerful we are.
 
 this has been discussed before, and i think this topic is irrelevant,
 since we do not agree that minds are necessary, and neither do
 physicists. 
 
 > anyway, i'm speculating that minds would be in part x. there seems to
 > be some link between consciousness and r, in that we never see linear
 > superpositions of anything, although there are alternative
 > explainations for this. i've no idea how a brain is supposed to access
 > part x, but since this is only speculation, that won't matter too
 > much :-) my main point is that there might be a place for minds in
 > physics.
 
 i agree, but not in the sense you apparently mean above - physics
 needs sharp minds to solve many real problems. ;-)
 
 > i'll go back to my nice padded cell now, if that's ok with you :-)
 
 it's ok, if you don't forget to take with you the references i
 wrote about in my previous posting, plus the following:
 
 kalat, james w. (1988): biological psychology.
 3rd ed., wadsworth publishing company, belmont, ca 1988.
 
 skarda, c. (1985): explaining behavior: bringing the brain back in.
 inquiry 29:187-202.
 
 skarda, c. & freeman, w. (1987): how brains make chaos in order to
 make sense of the world. 
 behavioral and brain sciences 10:161-173.
 
 petri
 
 --
  ___. .'*''.*        petri pihko    kem-pmp@          mathematics is the truth.
 !___.'* '.'*' ' .    pihatie 15 c    finou.oulu.fi    physics is the rule of
        ' *' .* '*    sf-90650 oulu  kempmp@           the game.
           *'  *  .*  finland         phoenix.oulu.fi  -> chemistry is the game.
 